Job title,Posted,Payment info,Description
Need To Make A Scraping Tool,Posted 30 minutes ago,Fixed price Intermediate Est. budget: $155.00 ," I need to make a scraping tool that uses the search engine to find leads. We will just search for something and it gives a complete scraped data for leads and exports it to Excel

The tool should ask us what fields we need and then find the data accordingly "
"Automate SEO Article Writing - Web Scraping, OpenAI API GPT Analysis, Result Fine-Tuning",Posted 2 hours ago,"Hourly: $8.00 - $25.00  Intermediate  Est. time: 3 to 6 months, Less than 30 hrs/week"," Seeking an expert to help automate SEO article content creation. You'll create an automated content program in make.com or Zapier that can be operated by in-house content producers, and help us fine-tune it along the way.

General thrust of work:

- Scrape top 20 Google results for any given keyword
- Analyze scraped results with OpenAI GPT
	- Most common topics covered
	- Least common topics covered
	- ""Surprising"" topics covered
- Have GPT create outlines from scraped results based on that analysis
- Have GPT create articles section-by-section, and have GPT:
	- Suggest areas to add fresh data to 
	- Suggest where to find and add personal experiences, either from interviews or web research
	- Suggest when isn't certain about a fact it's added

If you've done this type of automation before, we hope you have other suggestions. "
Script to enter data from excel into webpage,Posted 3 hours ago,"Hourly: $20.00 - $40.00  Entry Level  Est. time: Less than 1 month, Less than 30 hrs/week"," I am looking for a basic script that can take data from my customer list in excel and enter it into my pricing website (mortgage lending). The pricing website will give multiple results at multiple prices. I would like the script to retrieve certain prices from this list and then export that data to a PDF file. It will need to have the ability to re-submit multiple scenarios into the pricing website and combine those onto a single PDF output.

The end goal is to take a list of 1000 customers and feed it into my pricing engine and generate quotes for the lowest rate, middle of the road, and lowest cost. I can specify further how exactly to determine these. "
Flights scraper for all award flights data,Posted 3 hours ago,"Hourly: $15.00 - $55.00  Expert  Est. time: More than 6 months, 30+ hrs/week"," I want to make a system like: https://pointsyeah.com/

they scrape all the airlines and get their award points data, I want the same to be done. This requires getting special access to endpoints and data points and may require login. We need to scrape them around 500k times a day

I want access to the following airlines:
- Qantas
- TAP Miles&Go
- Iberia Plus Avios
- Avianca LifeMiles
- Delta
- Singapore Airlines
- Emirates "
Need someone to improve my Pupeteer scraper,Posted 6 hours ago,Fixed price Expert Est. budget: $100.00 ," I already have a scraper written in pupeteer to scrape api calls from 1 website. My issue is the data on the site contains video and image, so after scraping for a few hours the chromium browser crashes due to there being too many media in cache.

I'm trying to cut down the media and css loaded on site but then the site detects that and stops showing any info.

So the help i need is either of the following, i do not have a preference as to which one is used. As long as i can scrape the data properly.

- Figure out a way to fix my script and not load media and css to prevent browser from crashing
-Reverse engineer their api, inspect to see how the site protects their api call, i tried copying out the CURL into postman but there's a recaptcha call to google before the api call that stops me from getting data successfully "
Implement a program in Python,Posted 7 hours ago,Fixed price Expert Est. budget: $600.00 ," 1) Finish developing and testing (have semi-working beta) content classification system that assess the quality of our website and blog content programmatically using the OpenAI API. High-quality content will be used to train the customer service bot. This includes tweaking existing web scraping and content classification code.

2) Implement a beta chatbot using Voiceflow front-end (internally first, maybe beta for existing customers or as a lead magnet for prospects) that accurately answers customer questions 70% of customer queries using our Knowledge Base (GitBook), our Blog, and distilled website/blog content (from phase 1), leveraging AI models (GPT-4o, O1-preview, O1-mini) via the OpenAI API and Python libraries. NOTE: can use old customer Q&As from zoho tickets as training as well. Would need to be cleaned and maybe classified as well.
2.1: Chatbot should have the ability to schedule client meetings with customer success and sales (create sub-workflows in voiceflow chatbot that handle this when the bot is asked certain keywords)
Phase 2.2: Chatbot should have some basic customer information (name, account, type of business) obtained via the our API to give relevant context


Phase 3: Enable the chatbot to generate Groovy formulas formatted for our mapping tools, leveraging  documentation and GPT-4 via the OpenAI API. Could be handled as a separate Voiceflow workflow specialized for this (auto switches with context)

Phase 4: Enhance the chatbot(s) to accept client sample data and reformat it for import into our systems, supporting four main import templates, utilizing Python data manipulation libraries like Pandas. May iterate on this as a separate chatbot before integrating into the existing one. Can deploy them separately internally/externally for testing. "
Automate Web Scraping and Checklist Download from Panini America Website Using Python,Posted 7 hours ago,Fixed price Intermediate Est. budget: $300.00 ," Project Overview:

I am looking to automate the process of downloading full checklists from the Panini America Checklist page (https://www.paniniamerica.net/checklist.html). 

The script should interact with multiple dropdowns in a specific sequence—Activity Type, Year Type, Brand Type, and Program Type—before downloading the full checklist for each combination of selections. 

The deliverables should include both the working Python code and all the downloaded .csv files.

Scope of Work:

Python Script Development:

The script should use Selenium (or a similar automation tool) to:

1. Open the webpage.

2. Select options in the following order:
a) Activity Type (dropdown-activity_type)
b) Year Type (dropdown-year_type)
c) Brand Type (dropdown-brand_type)
d) Program Type (dropdown-program_type)

3. Submit the search form to trigger the checklist display.

4. Download the full checklist for each combination of selections.

5. Ensure that the downloaded files are saved in .csv format to a specified directory.

Handling Web Elements:

The script should accurately select and interact with elements using XPath, IDs, or CSS selectors. The key elements to target are:
- Activity Type Dropdown (id=close-dropdown-activity_type).
- Year Type Dropdown (id=close-dropdown-year_type).
- Brand Type Dropdown (id=close-dropdown-brand_type).
- Program Type Dropdown (id=close-dropdown-program_type).
- Download Button for the checklist (e.g., using an XPath to identify the link to the .csv file).

Download the Files:

For each valid combination of dropdown selections, the script should:
- Submit the form to trigger the display of results.
- Locate and click the download link for the full checklist.
- Save each file as a .csv.

Error Handling and Logging:

Implement error handling to manage cases where no checklist is available for a given combination of selections.

The script should log which combinations were processed successfully and report any that failed or returned no checklist.

Deliverables:

A fully functional Python script that automates the entire process.

A folder containing all the downloaded .csv files from the website.

Additional Details:

Dropdown Interaction: The script should cycle through all valid combinations of the following dropdowns in this specific order:

a) Activity Type
b) Year Type
c) Brand Type
d) Program Type

After making the selections, it should submit the form, wait for the results to load, and then download the checklist.

Waiting for Page Load: The script should include appropriate wait times or use explicit waits to ensure that the results are fully loaded before attempting to download.

Efficiency: The script should be designed to minimize redundant actions (e.g., downloading duplicate checklists for identical combinations) and ensure smooth execution.

Timeline:

I would like the project to be completed within 7 days

Skills Required:

Expertise in Python and web automation using Selenium or a similar tool.

Experience with interacting dynamically with dropdowns and handling form submissions.

Familiarity with automating file downloads and managing large sets of combinations programmatically. "
Scrapy Developer Needed for Web Scraping Project,Posted 9 hours ago,"Hourly: $5.00 - $15.00  Intermediate  Est. time: 1 to 3 months, 30+ hrs/week"," We are seeking an experienced Scrapy developer to assist us with a web scraping project. The ideal candidate will have a strong background in developing scraping solutions using Scrapy and other related frameworks. You will be responsible for creating and maintaining efficient data extraction scripts while ensuring compliance with website policies. If you have a knack for solving complex scraping challenges and can deliver quality results on time, we want to hear from you! "
Looking for skilled AI Developer,Posted yesterday,"Fixed price Expert Est. budget: $25,000.00 "," We are building an innovative AI-driven platform aimed at social media content creation.

Key Responsibilities:

Design and Develop the MVP for an AI-driven platform.
Integrate AI/ML tools (like GPT-4 or other models).
Build systems for scraping or using APIs to gather social media date data (hashtags, engagement metrics, competitor posts).
Develop a user interface where users can input preferences, competitors, and receive AI-generated content.
Implement backend infrastructure to manage user inputs, AI-generated outputs, and content scheduling features.
Ensure data security and privacy, especially when handling social media account details (e.g., account access).
Provide basic analytics features: Analyze engagement and performance of posts.
Collaborate with stakeholders to iterate and improve the platform based on user feedback.

Required Skills and Experience:
Full-Stack Development:
Experience with frontend frameworks (React, Vue.js, or similar) to create an intuitive and user-friendly interface.
Strong proficiency in backend development (Node.js, Python, etc.), building RESTful APIs, and handling data.
AI and Machine Learning:
Expertise in Natural Language Processing (NLP) (e.g., GPT-4, OpenAI API, Hugging Face models) to generate captions and analyze Instagram data.
Experience with Machine Learning models for data analysis and trend prediction.
Ability to integrate and fine-tune AI models for content generation based on input parameters like niche, competitors, and design style.
Data Scraping and API Integration:
Experience with Instagram Graph API or similar third-party tools to gather data (hashtags, engagement, competitors' posts).
Knowledge of data scraping methods and tools to gather insights from competitor profiles and social media trends.
Database Management:
Proficiency in handling large datasets, managing user inputs, and storing AI-generated content securely.
Experience with database systems (e.g., PostgreSQL, MongoDB, etc.).

Security and Privacy:
Understanding of data privacy and best practices to secure user accounts (e.g., using tools like LastPass for account access).
Implement robust security protocols to safeguard user data, including encryption and access management.
User Experience and Interface Design:
Ability to create a clean, user-friendly interface where users can input parameters and generate content easily.
Experience designing responsive, visually appealing web applications.
Version Control and Collaboration:
Proficiency with version control systems like Git.
Experience collaborating with teams or stakeholders remotely, with strong communication and project management skills.

Preferred Qualifications:
Experience with social media platforms, particularly Instagram’s API, engagement metrics, and viral content strategies.
Knowledge of cloud services (e.g., AWS, GCP, or Azure) for hosting and scaling the platform.
Prior experience building AI-driven SaaS platforms or social media automation tools.
Strong problem-solving skills, with the ability to iterate and adapt based on user feedback.

Project Timeline:
The MVP should be completed within 1-3 months, with clear milestones for feature completion.
This role has the potential for ongoing collaboration as the platform evolves.

How to Apply:
If you're excited about the opportunity to work on cutting-edge AI-driven content solutions and have the skills to bring this vision to life, we’d love to hear from you! Please send your resume, portfolio, and a brief description of your relevant experience. Include links to any relevant projects you’ve worked on, particularly those related to AI, content generation, or social media tools. "
Amazon Product Scraper Needed for Rank and Video Analysis,Posted yesterday,"Fixed price Intermediate Est. budget: $1,000.00 "," We are seeking an experienced web scraper to help identify Amazon products ranked #10,000 or below with fewer than 2 videos on their product pages. The ideal candidate will possess strong scraping skills and be familiar with Amazon's product ranking system. You will be responsible for extracting relevant product data, ensuring accuracy, and delivering the findings in a structured format. If you have a knack for data analysis and a keen eye for detail, we want to hear from you! Please include examples of previous scraping projects in your application. "
Web Scraping Expert Needed,Posted yesterday,"Hourly: $12.00 - $25.00  Intermediate  Est. time: 1 to 3 months, Less than 30 hrs/week"," I’m looking for an experienced web scraping expert to help gather data from G2 and Capterra. The project involves scraping software listings, reviews, pricing information, and other relevant details. There may be CAPTCHA challenges or other website protections, so I need someone who knows how to navigate these smoothly.

Key Responsibilities:

Scrape data from G2 and Capterra, including software names, categories, reviews, ratings, and pricing.
Handle any CAPTCHA or bot detection issues that arise during scraping.
Deliver clean, structured data in CSV or Google Sheets format.
Requirements:

Proven experience in web scraping and dealing with website protections.
Familiarity with tools like Octoparse, Scrapy, or Selenium.
Ability to work independently and deliver reliable results.
Experience scraping large websites is a plus.
If this sounds like something you can help with, please reach out with examples of your past work or a brief description of your approach to solving CAPTCHA and scraping protected sites. "
Data Scraping for Traffic Fines Information,Posted yesterday,"Hourly: $8.00 - $25.00  Intermediate  Est. time: 1 to 3 months, Less than 30 hrs/week"," We are seeking a skilled freelancer to perform data scraping to retrieve traffic fines information from a publicly available source. The ideal candidate should have experience in web scraping techniques and be familiar with handling and organizing data efficiently. Your work will aid in compiling the necessary information for analysis and reporting. If you are detail-oriented and have a strong background in data extraction, we would love to hear from you. "
build a custom scrapper for API documentation on Python,Posted yesterday,"Hourly: $20.00 - $45.00  Intermediate  Est. time: Less than 1 month, Less than 30 hrs/week"," We need a custom scrapper for API documentation that is intuitive and can capture from almost any site documentation section, return the data, and create a file in .json format "
Web Data Scraping Specialist Needed,Posted yesterday,"Hourly: $8.00 - $15.00  Intermediate  Est. time: 1 to 3 months, Less than 30 hrs/week"," We are looking for a skilled individual to assist us in scraping data from various websites. The ideal candidate will have experience with web scraping tools and techniques to efficiently extract relevant information. You will be responsible for collecting, organizing, and delivering the data in a structured format. Attention to detail and the ability to work independently are crucial for this role. If you have the expertise to help us gather data effectively, we would love to hear from you!

The websites we're looking at:
https://capology.com/uk/premier-league/salaries/ to collect information about players' salaries
https://www.whoscored.com/ to collect all the information of players during the game "
Coder to help scrape public data from the web about FTSE 250 consultancies,Posted yesterday,"Hourly: $8.00 - $25.00  Intermediate  Est. time: 1 to 3 months, Less than 30 hrs/week"," Hello, I am interested in compiling data on the FTSE 250 companies in the UK. I want to particularly know (1) who is currently their financial PR firm and when were they hired, (2) who is currently their public affairs firm and when were they hired. 

I believe that this would all be public data. 

For (1) you would need to look at RNS announcements. These can be found on websites like LSE (https://www.lse.co.uk/rns/ftse-250.html for example). From here you can uncover the email addresses / names of firms listed as ‘media contacts’ usually at the bottom of company announcements. If you went back far enough you could then also see when the firm was hired (i.e. when were they first included in the RNS as media contact). 

For (2) you should use the two public registers for public affairs firms, and see which have listed FTSE 250 companies as clients and (ideally) when were they first entered in to the register. These websites are:
-	PRCA Register: https://register.prca.org.uk/register/current-register/
-	Consultant Lobbyist Register: https://orcl.my.site.com/CLR_Annual_Returns_Downloads

I’d be interested to know if you think this is possible through some form of web scraping / bot. If so, I’d be interested to know how much this would cost. "
Modify Old Python Script that utilizes Fortran,Posted yesterday,Fixed price Intermediate Est. budget: $250.00 ," $1,300 BONUS: In addition to the $250 guaranteed project price, you will also be competing against other developers for a BONUS $1,300 prize pool based on how accurately your Global Surface Temp score matches the official published score. More details will be available once you apply.

I have an old Python script that uses Fortran for certain data preprocessing. It calculates the global monthly surface temperature based on 2 data files (one file for land temp data, and one for ocean temp data.)

Currently the script uses data files that are compiled monthly. I want you to 1) Download/Scrape daily data files which are available online and 2) Convert those files to a monthly format so they can be run through the script. "
Booking Bot Developer for Singapore Sport Facility(OCBC Sports Arena),Posted yesterday,Fixed price Intermediate Est. budget: $200.00 ," Pre-condition
The developer must create an account at OCBC Arena (https://sportshub.perfectgym.com/clientportal2/#/Login) for testing and development purposes.

Requirement
The booking bot should be developed with speed and efficiency in mind, considering the competitive environment where other users may also be utilizing bots. The following features are required:

Login Functionality:

The bot must allow login using a provided username and password and confirm successful login by displaying the user's first and last name as per the account profile.
Booking Preferences:

The bot must enable the selection of a specific date and time slot for booking.
It must allow the user to choose between the Local Resident Rate and the Standard Rate.
Badminton Court Booking:

The bot will only handle badminton court bookings and should attempt to book all available courts for the selected date and time, or allow the user to select a specific court to book.
Booking Confirmation:

Upon finding an available court, the bot must add the booking to the cart, marking the booking as successfully reserved. The user will manually complete the payment on the website.
Failure Handling:

In the event of a booking failure, the bot should immediately attempt to book other available courts for the same time slot.
Multiple Instances:

The bot should support running up to 3 instances simultaneously to improve booking success rates.
Performance Requirement:

The bot must achieve at least a 50% success rate in booking weekend time slots for the project to be considered complete. The developer is responsible for testing and verifying this success rate.

Milestone and budget breakdown
1. Functionality of the bot - 80
2. Success rate of 50% and above - 120

PLEASE READ CLEARLY ON THE ABOVE REQUIREMENT BEFORE DECIDING TO TAKE UP THIS PROJECT. I NEED THE HIRE TO EXPRESS INTEREST AND PROACTIVENESS. "
AI Tool for Law firms ,Posted yesterday,Fixed price Expert Est. budget: $500.00 ," Build a web based platform for users to 

1. Contract Review and Drafting

We expect our AI tools that assist in reviewing contracts for inconsistencies, risky clauses, and legal compliance. The tool can analyze large volumes of contracts quickly, flag potential issues, suggest modifications, and even automate standard contract generation.

 

2. Legal Research and Case Law Analysis

Legal professionals often rely on AI to expedite legal research. AI-powered platforms can scan vast databases of case law, statutes, and legal precedents to deliver relevant insights in a fraction of the time it would take a human researcher. Additionally, AI can provide case predictions by analyzing previous rulings, helping lawyers develop better strategies.

 

3. Document Automation

Automation of legal documents—such as wills, NDAs, incorporation papers, and legal forms—is another highly desired area. AI should be able to auto-generate documents based on templates and client inputs, significantly cutting down preparation time and ensuring accuracy.

 

4. Predictive Analytics

AI’s ability to predict case outcomes based on historical data is also important. We wish the AI tool to analyze judicial behavior, case law trends, and other data points to predict the likelihood of success in litigation.

 

5. Compliance and Risk Management

The AI tool can be used in compliance to help businesses stay updated with changing regulations, especially in highly regulated industries such as finance, healthcare, and technology. AI systems can monitor for changes in laws and regulations and flag non-compliance risks, helping companies avoid legal penalties.

 

6. Due Diligence in Mergers & Acquisitions

AI tool should be able to assist with due diligence by reviewing contracts, financial documents, and other materials to identify potential legal risks. "
Need a database of the betting line on Underdog and Prizepick.,Posted yesterday,Fixed price Intermediate Est. budget: $350.00 ," Hi,

Need the prop line for the whole websites for the following games :

- League of Legends
- Counter Strike 2
- Dota 2
- Valorant
- R7 Siege


It need to be updated every 10 minutes and stored in a database.

Any solution will do, need to be able to access the database later via a python interface, open to suggestion on how to do it.

Budget is 350 with a firm ceiling at 500$. "
Developer/Analyst to Identify Companies Sharing Video Data with Third Parties via APIs at Scale,Posted yesterday,"Hourly: $10.00 - $50.00  Intermediate  Est. time: Less than 1 month, Less than 30 hrs/week"," We are seeking an experienced research analyst to identify companies and services that are involved in sending video-related user data to third-party platforms such as Twilio, Facebook, and other API services. Your role will involve investigating various websites, apps, and video streaming platforms that might be violating privacy laws like the Video Privacy Protection Act (VPPA) by sharing Personally Identifiable Information (PII) and video-viewing information with third parties.

You will be required to perform thorough research on companies, test websites and apps, and analyze data flows to uncover where video data is shared without user consent. The goal is to create a comprehensive list of companies and detailed reports of the data-sharing practices. Most interested in a applicant that can do this at scale and find hundreds of companies.

Key Responsibilities:
Identify websites, apps, or platforms that stream video content and potentially share user data with third-party services (e.g., Twilio, Facebook, Vimeo, etc.).
Research platforms involved in streaming, video hosting, or providing video-related services like Vimeo OTT and Twilio's Segment API.
Dynamic Analysis of Websites and Apps:

Conduct dynamic analysis to detect data transmissions from video platforms to third-party services.
Use tools such as browser developer tools, network sniffers, or specialized privacy software (e.g., Fiddler, Wireshark) to capture and analyze the data exchanged between user devices and third parties when video content is viewed.
API and SDK Investigation:

Research the use of APIs and SDKs (e.g., Twilio Segment, Vimeo OTT) integrated into websites and apps.
Identify companies using these APIs and analyze how PII (e.g., names, emails, video titles) is being shared with third parties.
Compliance Check (VPPA & Other Privacy Laws):

Provide a report on each company, detailing their data-sharing practices, including:
The platform name and website.
Third parties receiving the data (e.g., Twilio, Facebook, Google).
Specific types of data shared (e.g., video titles, user IDs, emails).
Whether explicit user consent was obtained for sharing the data.
Highlight companies using video data for marketing, advertising, or analytics purposes.
Skills Required:
Research & Analysis:

Strong background in APIs and development.
Ability to identify and analyze websites and apps' use of APIs and data-sharing practices at scale.

Technical Tools Knowledge:
Experience using web development tools, network analysis software (e.g., Wireshark, Fiddler), and API inspection tools to capture and analyze data flows.
Understanding of API integrations, especially with platforms like Twilio, Vimeo, and Facebook.

Report Writing:
Excellent documentation and report-writing skills.
Ability to clearly present complex data and legal concepts in a detailed and professional report.

Deliverables:
A detailed list of companies sharing video-related PII with third parties, categorized by industry, platform, and third-party API.
Individual Reports: "
